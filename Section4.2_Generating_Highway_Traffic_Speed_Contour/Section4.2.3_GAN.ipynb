{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb583f7a-4b6f-4e98-af20-52e6eb869c62",
   "metadata": {},
   "source": [
    "# Section 4.2.3. GAN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ee43e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils import *\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb85577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Define the Generator and Discriminator\n",
    "# -------------------------------\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, input_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.gen_fc = nn.Sequential(\n",
    "            nn.Linear(z_dim, 128 * 8 * 8),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.gen_conv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(32, input_dim, 4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.gen_fc(x)\n",
    "        x = x.view(x.size(0), 128, 8, 8)\n",
    "        x = self.gen_conv(x)\n",
    "        return x\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc_conv = nn.Sequential(\n",
    "            nn.Conv2d(input_dim, 32, 4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(32, 64, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        self.disc_fc = nn.Sequential(\n",
    "            nn.Linear(128 * 8 * 8, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.disc_conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.disc_fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a880eb-d43d-4334-bfd4-6efaf5fae398",
   "metadata": {},
   "source": [
    "## 1. Training Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8123dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Training and loss calculation\n",
    "# -------------------------------\n",
    "def train_gan(generator, discriminator, data_loader, optim_gen, optim_disc, criterion, num_epochs, device, z_dim, real_label, fake_label):\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    total_samples = len(data_loader.dataset)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss_D = 0.0\n",
    "        running_loss_G = 0.0\n",
    "        for data in data_loader:\n",
    "            # --- Discriminator ---\n",
    "            discriminator.zero_grad()\n",
    "            real_data = data.to(device)\n",
    "            batch_size = real_data.size(0)\n",
    "            label = torch.full((batch_size,), real_label, device=device).float()\n",
    "\n",
    "            output = discriminator(real_data).view(-1)\n",
    "            errD_real = criterion(output, label)\n",
    "            errD_real.backward()\n",
    "\n",
    "            noise = torch.randn(batch_size, z_dim, device=device)\n",
    "            fake = generator(noise)\n",
    "            label.fill_(fake_label)\n",
    "            output = discriminator(fake.detach()).view(-1)\n",
    "            errD_fake = criterion(output, label)\n",
    "            errD_fake.backward()\n",
    "\n",
    "            errD = errD_real + errD_fake\n",
    "            optim_disc.step()\n",
    "            running_loss_D += errD.item() * batch_size\n",
    "\n",
    "            # --- Generator ---\n",
    "            generator.zero_grad()\n",
    "            label.fill_(real_label) \n",
    "            output = discriminator(fake).view(-1)\n",
    "            errG = criterion(output, label)\n",
    "            errG.backward()\n",
    "            optim_gen.step()\n",
    "            running_loss_G += errG.item() * batch_size\n",
    "\n",
    "        avg_loss_D = running_loss_D / total_samples\n",
    "        avg_loss_G = running_loss_G / total_samples\n",
    "        print(f'Epoch [{epoch+1:02}/{num_epochs}] Loss_D: {avg_loss_D:>6.4f} Loss_G: {avg_loss_G:>6.4f}')\n",
    "\n",
    "    return generator, discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377eb0d3-f589-4b75-abf1-eefe6295c522",
   "metadata": {},
   "source": [
    "![alt text](img/GAN_edit.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51de97f-f7f8-4a11-bc21-d0ab0488f1ec",
   "metadata": {},
   "source": [
    "The learning process is guided by a value function $V(\\phi, \\theta)$, defined as follows:\n",
    "\n",
    "- $V(\\phi, \\theta) = \\mathbb{E}_{\\mathbf{x} \\sim p_{data}(\\mathbf{x})}[\\log D_{\\phi}(\\mathbf{x})] + \\mathbb{E}_{\\mathbf{z} \\sim p(\\mathbf{z})}[\\log(1 - D_{\\phi}(G_{\\theta}(\\mathbf{z})))]$\n",
    "\n",
    "The learning process involves simultaneously optimizing the parameters of both $G$ and $D$, specifically $\\theta$ and $\\phi$, through gradient-based methods as shown below. This process alternates between the following two steps:\n",
    " \n",
    "\n",
    "- $ Goal: \\phi^{*},\\theta^{*} = \\min_{G_{\\theta}} \\max_{G_{\\phi}} V(\\phi, \\theta)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565c2f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../dataset/i24_normalized.pt'\n",
    "batch_size = 250\n",
    "z_dim = 64\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "num_epochs = 50\n",
    "real_label = 1.0\n",
    "fake_label = 0.0\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "dataset, data_loader = load_and_preprocess_data(data_path, batch_size)\n",
    "\n",
    "input_dim = dataset.shape[1] # dataset.shape: [40000, 1, 64, 64] â†’ input_dim = 1\n",
    "\n",
    "generator = Generator(z_dim, input_dim).to(device)\n",
    "discriminator = Discriminator(input_dim).to(device)\n",
    "\n",
    "optim_gen = torch.optim.Adam(generator.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optim_disc = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc936f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generator summary:\")\n",
    "summary(generator, (z_dim,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f38fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Discriminator summary:\")\n",
    "summary(discriminator, (input_dim, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ed4da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator, discriminator = train_gan(generator, discriminator, data_loader, optim_gen, optim_disc,\n",
    "                                        criterion, num_epochs, device, z_dim, real_label, fake_label)\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "torch.save(generator.state_dict(), 'models/generator.pth')\n",
    "torch.save(discriminator.state_dict(), 'models/discriminator.pth')\n",
    "print(\"Generator and Discriminator models saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5996651b-e547-4aa6-9552-8bc173a8d1a4",
   "metadata": {},
   "source": [
    "## 2. Testing Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96cdde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_generated_samples(generator, z_dim, device, nrows=8, ncols=8, save_path=\"img/GAN_result.png\"):\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(nrows * ncols, z_dim, device=device)\n",
    "        samples = generator(z).cpu().numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(nrows, ncols, figsize=(8, 8))\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            idx = i * ncols + j\n",
    "            ax[i, j].imshow(samples[idx][0, :, :], origin=\"lower\", cmap=\"viridis\")\n",
    "            ax[i, j].axis(\"off\")\n",
    "    plt.suptitle(\"Generated Samples\", fontsize=16)\n",
    "\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    plt.savefig(save_path, dpi=500)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45c3e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can use CPU in the inference, but highly recommended to use GPU\n",
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "generator = Generator(z_dim, input_dim).to(device)\n",
    "generator.load_state_dict(torch.load('models/generator.pth', map_location=device))\n",
    "generator.eval()\n",
    "\n",
    "visualize_generated_samples(generator, z_dim, device, nrows=8, ncols=8, save_path=\"img/GAN_result.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
